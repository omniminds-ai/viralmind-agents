import { describe, it, expect } from 'vitest';
import fs from 'fs';
import path from 'path';
import { PaintPipeline } from '../pipeline/paint-pipeline';
import { MessageFormatter } from '../stages/formatting/message-formatter';
import { OpenAIUtils } from '../shared/utils/openai';

// this uses the cached fine-tuning job
// turn this on when recording a demo so you don't have to wait 1 hour
const SKIP_FINETUNING = true;

describe('PaintPipeline - Fine-tuning Dataset Generation', () => {
    const NUM_TRAJECTORIES = 1; // Number of trajectories to generate
    const DATA_DIR = path.join(__dirname, '../../data');
    const METADATA_PATH = path.join(DATA_DIR, 'jspaint_0.json');
    const OUTPUT_DIR = path.join(DATA_DIR, 'finetune');

    // Create output directory if it doesn't exist
    if (!fs.existsSync(OUTPUT_DIR)) {
        fs.mkdirSync(OUTPUT_DIR, { recursive: true });
    }

    it('should generate fine-tuning dataset', { timeout: 20 * 60 * 1000 }, async () => {
        // Get list of available doodle files
        const doodleDir = path.join(DATA_DIR, 'doodles');
        const doodleFiles = fs.readdirSync(doodleDir)
            .filter(f => f.endsWith('.ndjson'))
            .map(f => f.replace('.ndjson', ''));

        // Initialize pipeline and formatter
        const pipeline = new PaintPipeline(DATA_DIR, METADATA_PATH);
        const formatter = new MessageFormatter();
        
        // Open write stream for JSONL output
        const outputPath = path.join(OUTPUT_DIR, `finetune_${NUM_TRAJECTORIES}_dataset.jsonl`);
        const writeStream = fs.createWriteStream(outputPath);
        
        // Stats tracking
        let totalMessages = 0;
        let imageMessages = 0;
        let textMessages = 0;
        let validTrajectories = 0;
        let skippedTrajectories = 0;
        
        // Generate trajectories
        for (let i = 0; i < NUM_TRAJECTORIES; i++) {
            // Generate events for 5 random doodles
            const events = await pipeline.process(doodleFiles, 2);
            
            // Format into messages
            const messages = await formatter.process(events);
            
            // Validate messages
            for (const msg of messages) {
                expect(msg).toHaveProperty('role');
                expect(msg).toHaveProperty('content');
                expect(msg).toHaveProperty('timestamp');
            }
            
            // Convert to OpenAI format
            const openaiMessages = OpenAIUtils.convertToOpenAIFormat(messages);

            // Check token count
            const tokenCount = OpenAIUtils.countConversationTokens(openaiMessages);
            if (tokenCount > OpenAIUtils.MAX_TOKENS) {
                console.log(`Skipping trajectory ${i + 1} - exceeds token limit (${tokenCount} tokens)`);
                skippedTrajectories++;
                continue;
            }

            // Update stats
            totalMessages += messages.length;
            imageMessages += messages.filter(m => 
                typeof m.content === 'object' && m.content.type === 'image'
            ).length;
            textMessages += messages.filter(m => 
                typeof m.content === 'string'
            ).length;
            validTrajectories++;
            
            // Write to file
            writeStream.write(JSON.stringify({ messages: openaiMessages }) + '\n');
            
            // Log progress
            console.log(`Generated trajectory ${i + 1}/${NUM_TRAJECTORIES} (${validTrajectories} valid, ${skippedTrajectories} skipped)`);
        }

        // Close write stream
        writeStream.end();

        // Generate stats
        const stats = {
            totalTrajectories: validTrajectories,
            skippedTrajectories,
            totalMessages,
            avgMessagesPerTrajectory: totalMessages / validTrajectories,
            imageMessages,
            textMessages
        };

        // Save stats
        const statsPath = path.join(OUTPUT_DIR, `dataset_${NUM_TRAJECTORIES}_stats.json`);
        fs.writeFileSync(statsPath, JSON.stringify(stats, null, 2));

        console.log('Dataset generation complete!');
        console.log('Stats:', stats);
        console.log(`Dataset saved to: ${outputPath}`);
        console.log(`Stats saved to: ${statsPath}`);
    });

    it('should finetune the painting model', { timeout: 120 * 60 * 1000 }, async () => {
        if (SKIP_FINETUNING) {
            console.log('fine-tuning skipped: model already exists!');
        } else {
            console.log('fine-tuning via openai lib not yet implemented');
            console.log('please upload the .jsonl to https://platform.openai.com/finetune/');
            return;
        }

        // Load and log finetuning stats
        const statsPath = path.join(DATA_DIR, 'finetuning_stats.json');
        const stats = JSON.parse(fs.readFileSync(statsPath, 'utf-8'));

        console.log('\nFinetuning Stats:');
        console.log('------------------');
        console.log(`Job ID: ${stats.jobId}`);
        console.log(`Model: ${stats.outputModel}`);
        console.log(`Trained Tokens: ${stats.trainedTokens.toLocaleString()}`);
        console.log(`Epochs: ${stats.epochs}`);
        console.log(`Batch Size: ${stats.batchSize}`);
        console.log(`Learning Rate Multiplier: ${stats.lrMultiplier}`);
        console.log(`Training Method: ${stats.trainingMethod}`);
        console.log(`Final Loss: ${stats.finalLoss}`);
        console.log(`Time Taken: ${stats.timeTaken}`);
        
        console.log('\nðŸŽŠ Your model has been trained!\n');

        // Calculate cost
        const costUSD = (stats.trainedTokens / 1_000_000) * 25;
        const costSOL = (costUSD * 0.10) / 25; // $25 = 0.10 SOL conversion
        console.log(`Cost: ${costSOL.toFixed(4)} SOL`);
    });
});
